apiVersion: apps/v1
kind: Deployment
metadata:
  name: faster-whisper
  namespace: faster-whisper
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: faster-whisper
  replicas: 1
  revisionHistoryLimit: 3
  strategy:
    type: Recreate 
  template:
    metadata:
      labels:
        app.kubernetes.io/name: faster-whisper
    spec:
      # Switch to the nvidia runtime class to get access to GPUs
      runtimeClassName: nvidia
  
      # This process is tiny, we have a 1050Ti-4GB, 1060-6GB, and 3060-12GB in the cluster. We won't restrict this to a specific node.
      nodeSelector:
        nvidia.com/gpu.present: "true"

      containers:
      - name: faster-whisper
        image: lscr.io/linuxserver/faster-whisper:2.5.0-gpu # https://hub.docker.com/r/linuxserver/faster-whisper/tags
        env:
        - name: PUID
          value: "1000"
        - name: PGID  
          value: "1000"
        - name: TZ
          value: America/Vancouver
        - name: WHISPER_MODEL
          value: tiny-int8
        - name: WHISPER_LANG
          value: en
        resources:
          limits:
            nvidia.com/gpu: '1'
        ports:
        - name: faster-whisper
          containerPort: 10300
        volumeMounts:
        - name: storage
          # Models are downloaded and stored in the root home directory
          mountPath: /config
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: faster-whisper-nfs-pvc