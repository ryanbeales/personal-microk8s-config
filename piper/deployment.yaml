apiVersion: apps/v1
kind: Deployment
metadata:
  name: piper
  namespace: piper
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: piper
  replicas: 1
  revisionHistoryLimit: 3
  strategy:
    type: Recreate 
  template:
    metadata:
      labels:
        app.kubernetes.io/name: piper
    spec:
      # Switch to the nvidia runtime class to get access to the GPU
      runtimeClassName: nvidia
      # Since we have both a 1060 and a 3060 in the cluster, ensure we run on the 
      # faster one by selecting the node with it in. I can't do this via auto generated
      # labels it seems - I could add the label, but this is less work)
      nodeName: crobceratops
      containers:
      - name: piper
        image: lscr.io/linuxserver/piper:1.4.0-gpu # https://hub.docker.com/r/linuxserver/piper/tags
        env:
        - name: PUID
          value: "1000"
        - name: PGID  
          value: "1000"
        - name: TZ
          value: America/Vancouver
        - name: PIPER_VOICE
          value: en_US-lessac-medium
        resources:
          limits:
            nvidia.com/gpu: '1'
        ports:
        - name: piper
          containerPort: 10200
        volumeMounts:
        - name: storage
          # Models are downloaded and stored in the root home directory
          mountPath: /config
      volumes:
      - name: storage
        hostPath:
          path: /stash/piper
          type: DirectoryOrCreate # if the directory does not exist then create it